{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; color: purple;\" markdown=\"1\">Econ 320 Python Lab Regression Analysis and Qualitative Regressors </h1>\n",
    "<h2 style=\"text-align: center; color: purple;\" markdown=\"1\">Handout # 11 </h2>\n",
    "\n",
    "Many variables of interest are qualitative rather than quantitative. Gender, race, marital status, level of education, ocupation, region, etc. Qualitative information is ussualy represented in regressions as binary or dummy variables which can only take a value zero or one. \n",
    "\n",
    "**The set up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wooldridge as woo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "\n",
    "from stargazer.stargazer import Stargazer\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variables \n",
    "\n",
    "Dummy variables can be used as regressors just as any other variables. The coefficient of a single dummy variable added to regression represents the difference in the intercepet between groups, see Wooldridge (2019, Section 7.2)\n",
    "\n",
    "Let's use an example in which we want to estimate a wage equation, and investigate what are the wage differences by gender. Once we have generated the dummy variable we just need to include it in our regression formula. \n",
    "\n",
    "We will use our wage1 dataset from Wooldridge. First we want to check how is our variable of interest distributed. The gender variable in this dataset can be found in the variable female. A dummy variable that takes the value of 1 if the individual is female and 0 if male. \n",
    "\n",
    "We are going to use the function `pd.crosstab(index=variable, columns=column names)` to see the distribution of gender in our data, this will create a frequency table with the number of women and men in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   count\n",
       "female       \n",
       "0         274\n",
       "1         252"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load wage1 data from wooldridge package\n",
    "wage1 = woo.dataWoo('wage1')\n",
    "\n",
    "pd.crosstab(index=wage1['female'],\n",
    "           columns='count')      # Name the count column\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the wage differences by gender. The regression equation will be the following formula\n",
    "\n",
    "Model 1 $$log(wage) = \\beta_0 + \\beta_1*female + \\beta_2*educ + \\beta_3*exper + \\beta_4*tenure$$\n",
    "Model 2 & 3 Restrict the data only for men and only for women $$log(wage) = \\beta_0 + \\beta_1*female + \\beta_2*educ + \\beta_3*exper + \\beta_4*tenure$$\n",
    "\n",
    "Model 4 Interact education, experience and tenure with female \n",
    "\n",
    "$$log(wage) = \\beta_0 + \\beta_1*female + \\beta_2*educ(female==0) + \\beta_3*exper(female==0) + \\\\ \\beta_4*tenure(female==0) + \\beta_5*educ(female==1) + \\beta_6*exper(female==1) + \\beta_7*tenure(female==1)$$\n",
    "\n",
    "* Run the regression that estimates the equation above\n",
    "* First by using the variable female as a regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>np.log(wage)</td>   <th>  R-squared:         </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   84.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>4.68e-55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:08:11</td>     <th>  Log-Likelihood:    </th> <td> -282.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   526</td>      <th>  AIC:               </th> <td>   574.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   521</td>      <th>  BIC:               </th> <td>   596.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.5013</td> <td>    0.102</td> <td>    4.920</td> <td> 0.000</td> <td>    0.301</td> <td>    0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>    <td>   -0.3011</td> <td>    0.037</td> <td>   -8.085</td> <td> 0.000</td> <td>   -0.374</td> <td>   -0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0875</td> <td>    0.007</td> <td>   12.605</td> <td> 0.000</td> <td>    0.074</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>     <td>    0.0046</td> <td>    0.002</td> <td>    2.845</td> <td> 0.005</td> <td>    0.001</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>    <td>    0.0174</td> <td>    0.003</td> <td>    5.835</td> <td> 0.000</td> <td>    0.012</td> <td>    0.023</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.037</td> <th>  Durbin-Watson:     </th> <td>   1.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  22.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.012</td> <th>  Prob(JB):          </th> <td>1.40e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.010</td> <th>  Cond. No.          </th> <td>    141.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           np.log(wage)   R-squared:                       0.392\n",
       "Model:                            OLS   Adj. R-squared:                  0.388\n",
       "Method:                 Least Squares   F-statistic:                     84.07\n",
       "Date:                Fri, 18 Nov 2022   Prob (F-statistic):           4.68e-55\n",
       "Time:                        01:08:11   Log-Likelihood:                -282.46\n",
       "No. Observations:                 526   AIC:                             574.9\n",
       "Df Residuals:                     521   BIC:                             596.2\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.5013      0.102      4.920      0.000       0.301       0.702\n",
       "female        -0.3011      0.037     -8.085      0.000      -0.374      -0.228\n",
       "educ           0.0875      0.007     12.605      0.000       0.074       0.101\n",
       "exper          0.0046      0.002      2.845      0.005       0.001       0.008\n",
       "tenure         0.0174      0.003      5.835      0.000       0.012       0.023\n",
       "==============================================================================\n",
       "Omnibus:                       12.037   Durbin-Watson:                   1.775\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               22.360\n",
       "Skew:                           0.012   Prob(JB):                     1.40e-05\n",
       "Kurtosis:                       4.010   Cond. No.                         141.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = smf.ols(formula='np.log(wage) ~ female + educ + exper + tenure', data=wage1)\n",
    "m1 = m1.fit()\n",
    "# print regression table:\n",
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Regression on Wages<br><table style=\"text-align:center\"><tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"4\"><em>Dependent variable:np.log(wage)</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">All</td><td colspan=\"1\">Only men</td><td colspan=\"1\">Only women</td><td colspan=\"1\">Interaction</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td></tr><tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">Intercept</td><td>0.501<sup>***</sup></td><td>0.322<sup>**</sup></td><td>0.356<sup>**</sup></td><td>0.322<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.102)</td><td>(0.139)</td><td>(0.141)</td><td>(0.135)</td></tr><tr><td style=\"text-align:left\">female</td><td>-0.301<sup>***</sup></td><td></td><td></td><td>0.034<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.037)</td><td></td><td></td><td>(0.199)</td></tr><tr><td style=\"text-align:left\">educ</td><td>0.087<sup>***</sup></td><td>0.096<sup>***</sup></td><td>0.080<sup>***</sup></td><td>0.096<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.007)</td><td>(0.009)</td><td>(0.010)</td><td>(0.009)</td></tr><tr><td style=\"text-align:left\">exper</td><td>0.005<sup>***</sup></td><td>0.008<sup>***</sup></td><td>0.002<sup></sup></td><td>0.008<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.002)</td><td>(0.002)</td><td>(0.002)</td><td>(0.002)</td></tr><tr><td style=\"text-align:left\">tenure</td><td>0.017<sup>***</sup></td><td>0.018<sup>***</sup></td><td>0.010<sup>*</sup></td><td>0.018<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.003)</td><td>(0.004)</td><td>(0.005)</td><td>(0.004)</td></tr><tr><td style=\"text-align:left\">educ:female</td><td></td><td></td><td></td><td>-0.016<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td>(0.014)</td></tr><tr><td style=\"text-align:left\">exper:female</td><td></td><td></td><td></td><td>-0.006<sup>*</sup></td></tr><tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td>(0.003)</td></tr><tr><td style=\"text-align:left\">tenure:female</td><td></td><td></td><td></td><td>-0.008<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td>(0.007)</td></tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>526</td><td>274</td><td>252</td><td>526</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.392</td><td>0.365</td><td>0.212</td><td>0.403</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.388</td><td>0.358</td><td>0.202</td><td>0.395</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.416 (df=521)</td><td>0.428 (df=270)</td><td>0.397 (df=248)</td><td>0.414 (df=518)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>84.072<sup>***</sup> (df=4; 521)</td><td>51.836<sup>***</sup> (df=3; 270)</td><td>22.233<sup>***</sup> (df=3; 248)</td><td>49.912<sup>***</sup> (df=7; 518)</td></tr><tr><td colspan=\"5\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"4\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also filter your data and create two separate equations but the most efficient way is to add the subset option inside the lm command data=subset()\n",
    "m2 = smf.ols(formula='np.log(wage) ~  educ + exper + tenure', \n",
    "             data=wage1, subset=(wage1['female']==0)).fit()\n",
    "m2.summary()\n",
    "#You need to interact each regressor with the female variable for the models to be the same \n",
    "# when you restrict the sample do it below in model m3\n",
    "\n",
    "m3 = smf.ols(formula='np.log(wage) ~ educ + exper + tenure', \n",
    "             data=wage1, subset=(wage1['female']==1)).fit()\n",
    "m3.summary()\n",
    "\n",
    "m4 = smf.ols(formula='np.log(wage) ~ educ*female + exper*female + tenure*female',\n",
    "             data=wage1).fit()\n",
    "m4.summary()\n",
    "# Put these models in stargazer table with the intercept at the bottom see the table \n",
    "# print regression table:\n",
    "\n",
    "models = Stargazer([m1, m2, m3, m4])\n",
    "models.title('Regression on Wages')\n",
    "models.custom_columns(['All', 'Only men', 'Only women', 'Interaction'], [1, 1, 1, 1])\n",
    "models.covariate_order(['Intercept', 'female' , 'educ' , 'exper', 'tenure', 'educ:female', 'exper:female','tenure:female'])\n",
    "HTML(models.render_html())\n",
    "\n",
    "\n",
    "# Now, what can you say about the coefficients for the dummy variable female?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variables and arithmetic formulas into a regression  \n",
    "\n",
    "We can run another regression with the following formula \n",
    "\n",
    "$$log(wage) = \\beta_0 + \\beta_1*married + \\beta_2*female + + \\beta_3*married*female + \\beta_4*educ + \\beta_5*exper + \\beta_6*exper^2 + \\beta_7*tenure + \\beta_8*tenure^2$$\n",
    "\n",
    "Notice how we are adding married and female dummy variables in the regression and also two squared variables into the regression \n",
    "\n",
    "These dummy variables are added as they are because they take 1 for category of interest and 0 for the other. \n",
    "\n",
    "When you want to add variables that are arithmetic operations of other variables instead of creating a separate variable you can add them just by using `I(formula)`\n",
    "\n",
    "* Run the new regression that estimates the new equation with tenure and experience squared \n",
    "* Run another regression with an interaction term of female and education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"3\"><em>Dependent variable:np.log(wage)</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">Intercept</td><td>0.321<sup>***</sup></td><td>0.390<sup>***</sup></td><td>0.390<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.100)</td><td>(0.119)</td><td>(0.119)</td></tr><tr><td style=\"text-align:left\">female</td><td>-0.110<sup>**</sup></td><td>-0.220<sup></sup></td><td>-0.220<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.056)</td><td>(0.168)</td><td>(0.168)</td></tr><tr><td style=\"text-align:left\">educ</td><td>0.079<sup>***</sup></td><td>0.081<sup>***</sup></td><td>0.081<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.007)</td><td>(0.009)</td><td>(0.009)</td></tr><tr><td style=\"text-align:left\">exper</td><td>0.027<sup>***</sup></td><td>0.027<sup>***</sup></td><td>0.027<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.005)</td><td>(0.005)</td><td>(0.005)</td></tr><tr><td style=\"text-align:left\">tenure</td><td>0.029<sup>***</sup></td><td>0.031<sup>***</sup></td><td>0.031<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.007)</td><td>(0.007)</td><td>(0.007)</td></tr><tr><td style=\"text-align:left\">married</td><td>0.213<sup>***</sup></td><td>0.053<sup></sup></td><td>0.053<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.055)</td><td>(0.041)</td><td>(0.041)</td></tr><tr><td style=\"text-align:left\">married:female</td><td>-0.301<sup>***</sup></td><td></td><td></td></tr><tr><td style=\"text-align:left\"></td><td>(0.072)</td><td></td><td></td></tr><tr><td style=\"text-align:left\">educ:female</td><td></td><td></td><td>-0.006<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.013)</td></tr><tr><td style=\"text-align:left\">I(exper ** 2)</td><td>-0.001<sup>***</sup></td><td>-0.001<sup>***</sup></td><td>-0.001<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.000)</td><td>(0.000)</td><td>(0.000)</td></tr><tr><td style=\"text-align:left\">I(tenure ** 2)</td><td>-0.001<sup>**</sup></td><td>-0.001<sup>**</sup></td><td>-0.001<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.000)</td><td>(0.000)</td><td>(0.000)</td></tr><tr><td style=\"text-align:left\">I(educ * female)</td><td></td><td>-0.006<sup></sup></td><td></td></tr><tr><td style=\"text-align:left\"></td><td></td><td>(0.013)</td><td></td></tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>526</td><td>526</td><td>526</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.461</td><td>0.443</td><td>0.443</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.453</td><td>0.434</td><td>0.434</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.393 (df=517)</td><td>0.400 (df=517)</td><td>0.400 (df=517)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>55.246<sup>***</sup> (df=8; 517)</td><td>51.353<sup>***</sup> (df=8; 517)</td><td>51.353<sup>***</sup> (df=8; 517)</td></tr><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"3\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = smf.ols(formula='np.log(wage) ~ married*female + educ + exper +' \n",
    "              'I(exper**2) + tenure + I(tenure**2)', data=wage1)\n",
    "results = reg.fit()\n",
    "#results.summary()\n",
    "\n",
    "reg1 = smf.ols(formula='np.log(wage) ~ married + educ + female + I(educ*female) + exper +'\n",
    "               'I(exper**2) + tenure + I(tenure**2)', data=wage1)\n",
    "results1 = reg1.fit()\n",
    "#resulst.summary()\n",
    "\n",
    "reg2 = smf.ols(formula='np.log(wage) ~ married + educ*female + exper +' \n",
    "              'I(exper**2) + tenure +I(tenure**2)', data=wage1)\n",
    "results2 = reg2.fit()\n",
    "#resulst.summary() \n",
    "\n",
    "model4 = Stargazer([results, results1, results2])\n",
    "model4.covariate_order(['Intercept','female' , 'educ' , 'exper', 'tenure', 'married',\n",
    "                        'married:female' , 'educ:female', 'I(exper ** 2)', 'I(tenure ** 2)', 'I(educ * female)'])\n",
    "HTML(model4.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The other option use only the interaction, there is no need to include the variables alone Python does it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Variables\n",
    "\n",
    "To store qualitative yes or no information Python uses **Boolean variables**. Instead of transforming boolean variables into 0/1 dummy variables tehy can be directly used as regressors in the output their coefficient is then named `varname[T.True]`. These variables are treated such that **TRUE=1** and **FALSE=0**.\n",
    "\n",
    "Below we will take the femail dummy variable and recoded as a boolean variable and introduce it in the regression. See below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    274\n",
       "True     252\n",
       "Name: isfemale, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the boolean variable form femal dummy \n",
    "wage1['isfemale'] = (wage1['female']==1)\n",
    "\n",
    "wage1['isfemale'].value_counts()\n",
    "#wage1[['isfemale']].describe()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with logical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable:np.log(wage)</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">Intercept</td><td>0.501<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.102)</td></tr><tr><td style=\"text-align:left\">Female:True</td><td>-0.301<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.037)</td></tr><tr><td style=\"text-align:left\">educ</td><td>0.087<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.007)</td></tr><tr><td style=\"text-align:left\">exper</td><td>0.005<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.002)</td></tr><tr><td style=\"text-align:left\">tenure</td><td>0.017<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.003)</td></tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>526</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.392</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.388</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.416 (df=521)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>84.072<sup>***</sup> (df=4; 521)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"1\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regression with boolean variable:\n",
    "m6 = smf.ols(formula='np.log(wage) ~ isfemale + educ + exper + tenure', data = wage1)\n",
    "m6 = m6.fit()\n",
    "\n",
    "\n",
    "\n",
    "m6s = Stargazer([m6])\n",
    "m6s.covariate_order(['Intercept','isfemale[T.True]' , 'educ' , 'exper', 'tenure'])\n",
    "m6s.rename_covariates({'isfemale[T.True]': 'Female:True'})\n",
    "HTML(m6s.render_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variables\n",
    "\n",
    "\n",
    "When estimating a linear regression in python using **statsmodels** you can easily transform any variable into a categorical variable using the function `C()` in the definition of the formula. Our **ols** function will add *g-1* dummy variables if the vairbale has *g* categories. As a refrence category the first category is left out by default. \n",
    "\n",
    "When you use categorical variables that have many categories, you have to choose a reference category and this is the ommitted variable that you use to avoid colinearity. By default the first category is left out in Python but we can use a second argument in the `C()` command where we procide a new reference group `somegroup` with the using the command **Treament(\"somegroup\")**. \n",
    "\n",
    "The code below shows how our categorical variables are used variables are used.\n",
    "\n",
    "* Table of categories and frequencies for two factor variables gender and occupation:\n",
    "* What type of variable is occupation\n",
    "* Regression with dummies for many categories from a categorical variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPS1985 = pd.read_csv('/Users/yifeng/Downloads/CPS1985.csv')\n",
    "# rename variable to make outputs more compact:\n",
    "CPS1985['oc'] = CPS1985['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   count\n",
       "gender       \n",
       "female    245\n",
       "male      289"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table of categories and frequencies for two categorical variables:\n",
    "pd.crosstab(CPS1985['gender'], columns='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oc</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>office</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>services</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technical</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worker</th>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       count\n",
       "oc               \n",
       "management     55\n",
       "office         97\n",
       "sales          38\n",
       "services       83\n",
       "technical     105\n",
       "worker        156"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_occupation = pd.crosstab(CPS1985['oc'], columns = 'count')\n",
    "freq_occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable:np.log(wage)</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">C(oc)[T.office]</td><td>-0.291<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.078)</td></tr><tr><td style=\"text-align:left\">C(oc)[T.sales]</td><td>-0.369<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.096)</td></tr><tr><td style=\"text-align:left\">C(oc)[T.services]</td><td>-0.397<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.084)</td></tr><tr><td style=\"text-align:left\">C(oc)[T.technical]</td><td>-0.041<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.076)</td></tr><tr><td style=\"text-align:left\">C(oc)[T.worker]</td><td>-0.098<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.078)</td></tr><tr><td style=\"text-align:left\">Intercept</td><td>0.996<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.175)</td></tr><tr><td style=\"text-align:left\">education</td><td>0.080<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.010)</td></tr><tr><td style=\"text-align:left\">experience</td><td>0.011<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.002)</td></tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>534</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.281</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.272</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.450 (df=526)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>29.416<sup>***</sup> (df=7; 526)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"1\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directly using categorical variables in regression formula:\n",
    "m7 = smf.ols(formula='np.log(wage) ~ education + experience + C(oc)', data=CPS1985)\n",
    "m7 = m7.fit()\n",
    "\n",
    "# print regression table:\n",
    "m7s = Stargazer([m7])\n",
    "\n",
    "HTML(m7s.render_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a new the reference category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable:np.log(wage)</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">C(gender, Treatment(\"male\"))[T.female]</td><td>-0.224<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.042)</td></tr><tr><td style=\"text-align:left\">C(oc, Treatment(\"technical\"))[T.management]</td><td>0.010<sup></sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.074)</td></tr><tr><td style=\"text-align:left\">C(oc, Treatment(\"technical\"))[T.office]</td><td>-0.197<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.068)</td></tr><tr><td style=\"text-align:left\">C(oc, Treatment(\"technical\"))[T.sales]</td><td>-0.350<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.086)</td></tr><tr><td style=\"text-align:left\">C(oc, Treatment(\"technical\"))[T.services]</td><td>-0.353<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.075)</td></tr><tr><td style=\"text-align:left\">C(oc, Treatment(\"technical\"))[T.worker]</td><td>-0.142<sup>**</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.070)</td></tr><tr><td style=\"text-align:left\">Intercept</td><td>1.119<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.176)</td></tr><tr><td style=\"text-align:left\">education</td><td>0.076<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.010)</td></tr><tr><td style=\"text-align:left\">experience</td><td>0.012<sup>***</sup></td></tr><tr><td style=\"text-align:left\"></td><td>(0.002)</td></tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Observations</td><td>534</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.318</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.307</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.439 (df=525)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>30.572<sup>***</sup> (df=8; 525)</td></tr><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td>\n",
       " <td colspan=\"1\" style=\"text-align: right\">\n",
       "  <sup>*</sup>p&lt;0.1;\n",
       "  <sup>**</sup>p&lt;0.05;\n",
       "  <sup>***</sup>p&lt;0.01\n",
       " </td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rerun regression with different reference category:\n",
    "reg_newref = smf.ols(formula='np.log(wage) ~ education + experience + '\n",
    "                    'C(gender, Treatment(\"male\")) + ' \n",
    "                     'C(oc,Treatment(\"technical\"))', data=CPS1985)\n",
    "\n",
    "m8 = reg_newref.fit()\n",
    "\n",
    "# print regression table:\n",
    "m8s = Stargazer([m8])\n",
    "HTML(m8s.render_html())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anova tables \n",
    "\n",
    "When working with categorical variables, polynomials or orther specifications, the influence of one variables is capture by several regressors. In our example below the effect of occupation is captured by five regressors of their respective dummy variables. \n",
    "\n",
    "Our model is of the form:\n",
    "\n",
    "$$log(wage) = \\beta_0 + \\beta_1* education + \\beta_2*experience + \\\\  \\beta_3*gender + \\beta_4*office + \\beta_5*sales + \\beta_6*services + \\beta_7*technical  + \\beta_8*worker + u $$\n",
    "\n",
    "The significance of occupation can be assessed using an F test of \n",
    "\n",
    "$$ H_0: \\beta_4 = \\beta_5 = \\beta_6 = \\beta_7 = \\beta_8 = 0.$$\n",
    "\n",
    "A type II ANOVA (analysis of variance) table does exactly this for each variable in the model and displays the results in a clearly arranged table. **statsmodel implements this method `anova_lm`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>np.log(wage)</td>   <th>  R-squared:         </th> <td>   0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   30.57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>2.55e-39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:08:11</td>     <th>  Log-Likelihood:    </th> <td> -313.80</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   534</td>      <th>  AIC:               </th> <td>   645.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   525</td>      <th>  BIC:               </th> <td>   684.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>    0.9050</td> <td>    0.172</td> <td>    5.272</td> <td> 0.000</td> <td>    0.568</td> <td>    1.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender[T.male]</th>          <td>    0.2238</td> <td>    0.042</td> <td>    5.298</td> <td> 0.000</td> <td>    0.141</td> <td>    0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occupation[T.office]</th>    <td>   -0.2073</td> <td>    0.078</td> <td>   -2.670</td> <td> 0.008</td> <td>   -0.360</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occupation[T.sales]</th>     <td>   -0.3601</td> <td>    0.094</td> <td>   -3.846</td> <td> 0.000</td> <td>   -0.544</td> <td>   -0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occupation[T.services]</th>  <td>   -0.3626</td> <td>    0.082</td> <td>   -4.430</td> <td> 0.000</td> <td>   -0.523</td> <td>   -0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occupation[T.technical]</th> <td>   -0.0101</td> <td>    0.074</td> <td>   -0.136</td> <td> 0.892</td> <td>   -0.155</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>occupation[T.worker]</th>    <td>   -0.1525</td> <td>    0.076</td> <td>   -1.998</td> <td> 0.046</td> <td>   -0.303</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education</th>               <td>    0.0759</td> <td>    0.010</td> <td>    7.545</td> <td> 0.000</td> <td>    0.056</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>experience</th>              <td>    0.0119</td> <td>    0.002</td> <td>    7.089</td> <td> 0.000</td> <td>    0.009</td> <td>    0.015</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>22.197</td> <th>  Durbin-Watson:     </th> <td>   1.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  48.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.187</td> <th>  Prob(JB):          </th> <td>2.84e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.429</td> <th>  Cond. No.          </th> <td>    257.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           np.log(wage)   R-squared:                       0.318\n",
       "Model:                            OLS   Adj. R-squared:                  0.307\n",
       "Method:                 Least Squares   F-statistic:                     30.57\n",
       "Date:                Fri, 18 Nov 2022   Prob (F-statistic):           2.55e-39\n",
       "Time:                        01:08:11   Log-Likelihood:                -313.80\n",
       "No. Observations:                 534   AIC:                             645.6\n",
       "Df Residuals:                     525   BIC:                             684.1\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                   0.9050      0.172      5.272      0.000       0.568       1.242\n",
       "gender[T.male]              0.2238      0.042      5.298      0.000       0.141       0.307\n",
       "occupation[T.office]       -0.2073      0.078     -2.670      0.008      -0.360      -0.055\n",
       "occupation[T.sales]        -0.3601      0.094     -3.846      0.000      -0.544      -0.176\n",
       "occupation[T.services]     -0.3626      0.082     -4.430      0.000      -0.523      -0.202\n",
       "occupation[T.technical]    -0.0101      0.074     -0.136      0.892      -0.155       0.135\n",
       "occupation[T.worker]       -0.1525      0.076     -1.998      0.046      -0.303      -0.003\n",
       "education                   0.0759      0.010      7.545      0.000       0.056       0.096\n",
       "experience                  0.0119      0.002      7.089      0.000       0.009       0.015\n",
       "==============================================================================\n",
       "Omnibus:                       22.197   Durbin-Watson:                   1.887\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               48.572\n",
       "Skew:                          -0.187   Prob(JB):                     2.84e-11\n",
       "Kurtosis:                       4.429   Cond. No.                         257.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run regression:\n",
    "reg = smf.ols(\n",
    "    formula='np.log(wage) ~ education + experience + gender + occupation',\n",
    "    data=CPS1985)\n",
    "results = reg.fit()\n",
    "\n",
    "\n",
    "# print regression table:\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > See anova table below, column df in dicates that this test uses 5 parameters.  All other variables enter the table with a single parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>5.414018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.067296</td>\n",
       "      <td>1.727015e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>7.152529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.416013</td>\n",
       "      <td>9.805485e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>10.980589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.925450</td>\n",
       "      <td>2.010374e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>9.695055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.261001</td>\n",
       "      <td>4.365391e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>101.269451</td>\n",
       "      <td>525.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum_sq     df          F        PR(>F)\n",
       "gender        5.414018    1.0  28.067296  1.727015e-07\n",
       "occupation    7.152529    5.0   7.416013  9.805485e-07\n",
       "education    10.980589    1.0  56.925450  2.010374e-13\n",
       "experience    9.695055    1.0  50.261001  4.365391e-12\n",
       "Residual    101.269451  525.0        NaN           NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANOVA table:\n",
    "table_anova = sm.stats.anova_lm(results, typ=2)\n",
    "table_anova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Numeric variables into categories\n",
    "\n",
    "Sometimes we need to make numerical variables into categories because a linear relation with the dependent variable seems implausible or the interpretation is inconvenient. Or we simply want to have a different interpretation. \n",
    "\n",
    "In the example below the variable `rank` is the rank of the law school as a number between 1 and 175. We would like to compare schools in the different groups like in list below\n",
    "\n",
    "|School Rank | \n",
    "|-----------| \n",
    "|top 10 |\n",
    "|11-25 |\n",
    "|26-40 |\n",
    "|41-60 |\n",
    "|60-100 | \n",
    "|above 100 | \n",
    "\n",
    "\n",
    "In the code below we create variable for these categories. First define cut point and then create a new factor (categorical) variable based on these cut points using the cut command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rc</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top 10</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(10, 25]</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(25, 40]</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(40, 60]</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(60, 100]</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(100, 175]</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       count\n",
       "rc               \n",
       "top 10         10\n",
       "(10, 25]       16\n",
       "(25, 40]       13\n",
       "(40, 60]       18\n",
       "(60, 100]      37\n",
       "(100, 175]     62"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lawsch85 = woo.dataWoo('lawsch85')\n",
    "\n",
    "# define cut points for the rank:\n",
    "cutpts = [0, 10, 25, 40, 60, 100, 175]\n",
    "\n",
    "\n",
    "# create categorical variable containing ranges for the rank:\n",
    "lawsch85['rc'] = pd.cut(lawsch85['rank'], bins=cutpts,\n",
    "                       labels=['top 10', '(10, 25]', '(25, 40]',\n",
    "                               '(40, 60]', '(60, 100]', '(100, 175]'])\n",
    "\n",
    "\n",
    "# display frequencies:\n",
    "freq = pd.crosstab(lawsch85['rc'], columns='count')\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the following equation $$ log(salary)= \\beta_0 +\\beta_1*rankcat + \\beta_2*LSAT + \\beta_3*GPA + \\beta_4*log(libvol) + \\beta_5*log(cost)$$ But first follow the instructions to set the reference category, for the school ranking. \n",
    "\n",
    ">  Choose reference category, we want the last group as the reference category, so we use relevel. Save that in a new variable called rankcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>np.log(salary)</td>  <th>  R-squared:         </th> <td>   0.911</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   143.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 18 Nov 2022</td> <th>  Prob (F-statistic):</th> <td>9.45e-62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:10:50</td>     <th>  Log-Likelihood:    </th> <td>  146.45</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   136</td>      <th>  AIC:               </th> <td>  -272.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   126</td>      <th>  BIC:               </th> <td>  -243.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                       <td></td>                          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                   <td>    9.1653</td> <td>    0.411</td> <td>   22.277</td> <td> 0.000</td> <td>    8.351</td> <td>    9.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rc, Treatment(\"(100, 175]\"))[T.top 10]</th>    <td>    0.6996</td> <td>    0.053</td> <td>   13.078</td> <td> 0.000</td> <td>    0.594</td> <td>    0.805</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rc, Treatment(\"(100, 175]\"))[T.(10, 25]]</th>  <td>    0.5935</td> <td>    0.039</td> <td>   15.049</td> <td> 0.000</td> <td>    0.515</td> <td>    0.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rc, Treatment(\"(100, 175]\"))[T.(25, 40]]</th>  <td>    0.3751</td> <td>    0.034</td> <td>   11.005</td> <td> 0.000</td> <td>    0.308</td> <td>    0.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rc, Treatment(\"(100, 175]\"))[T.(40, 60]]</th>  <td>    0.2628</td> <td>    0.028</td> <td>    9.399</td> <td> 0.000</td> <td>    0.207</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rc, Treatment(\"(100, 175]\"))[T.(60, 100]]</th> <td>    0.1316</td> <td>    0.021</td> <td>    6.254</td> <td> 0.000</td> <td>    0.090</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSAT</th>                                        <td>    0.0057</td> <td>    0.003</td> <td>    1.858</td> <td> 0.066</td> <td>   -0.000</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GPA</th>                                         <td>    0.0137</td> <td>    0.074</td> <td>    0.185</td> <td> 0.854</td> <td>   -0.133</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.log(libvol)</th>                              <td>    0.0364</td> <td>    0.026</td> <td>    1.398</td> <td> 0.165</td> <td>   -0.015</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.log(cost)</th>                                <td>    0.0008</td> <td>    0.025</td> <td>    0.033</td> <td> 0.973</td> <td>   -0.049</td> <td>    0.051</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 9.419</td> <th>  Durbin-Watson:     </th> <td>   1.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.009</td> <th>  Jarque-Bera (JB):  </th> <td>  20.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.100</td> <th>  Prob(JB):          </th> <td>3.57e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.890</td> <th>  Cond. No.          </th> <td>8.98e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.98e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         np.log(salary)   R-squared:                       0.911\n",
       "Model:                            OLS   Adj. R-squared:                  0.905\n",
       "Method:                 Least Squares   F-statistic:                     143.2\n",
       "Date:                Fri, 18 Nov 2022   Prob (F-statistic):           9.45e-62\n",
       "Time:                        01:10:50   Log-Likelihood:                 146.45\n",
       "No. Observations:                 136   AIC:                            -272.9\n",
       "Df Residuals:                     126   BIC:                            -243.8\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================================\n",
       "                                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                       9.1653      0.411     22.277      0.000       8.351       9.979\n",
       "C(rc, Treatment(\"(100, 175]\"))[T.top 10]        0.6996      0.053     13.078      0.000       0.594       0.805\n",
       "C(rc, Treatment(\"(100, 175]\"))[T.(10, 25]]      0.5935      0.039     15.049      0.000       0.515       0.672\n",
       "C(rc, Treatment(\"(100, 175]\"))[T.(25, 40]]      0.3751      0.034     11.005      0.000       0.308       0.443\n",
       "C(rc, Treatment(\"(100, 175]\"))[T.(40, 60]]      0.2628      0.028      9.399      0.000       0.207       0.318\n",
       "C(rc, Treatment(\"(100, 175]\"))[T.(60, 100]]     0.1316      0.021      6.254      0.000       0.090       0.173\n",
       "LSAT                                            0.0057      0.003      1.858      0.066      -0.000       0.012\n",
       "GPA                                             0.0137      0.074      0.185      0.854      -0.133       0.161\n",
       "np.log(libvol)                                  0.0364      0.026      1.398      0.165      -0.015       0.088\n",
       "np.log(cost)                                    0.0008      0.025      0.033      0.973      -0.049       0.051\n",
       "==============================================================================\n",
       "Omnibus:                        9.419   Durbin-Watson:                   1.926\n",
       "Prob(Omnibus):                  0.009   Jarque-Bera (JB):               20.478\n",
       "Skew:                           0.100   Prob(JB):                     3.57e-05\n",
       "Kurtosis:                       4.890   Cond. No.                     8.98e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.98e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run regression:\n",
    "reg = smf.ols(formula='np.log(salary) ~ C(rc, Treatment(\"(100, 175]\")) +'\n",
    "              'LSAT + GPA + np.log(libvol)+ np.log(cost)',\n",
    "              data=lawsch85)\n",
    "results = reg.fit()\n",
    "\n",
    "# print regression table\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical dependent variables \n",
    "\n",
    "When you have a categorical dependent variable you can use regular OLS model, this will be a linear probability model LPM or you can use logit or probit models.\n",
    "\n",
    "The Python code for these last two models is:\n",
    "\n",
    "# Estimate logit model:\n",
    "\n",
    "Your y variable is binary 0 or 1 \n",
    "\n",
    ">`reg_logit = smf.logit(formula='y ~ x1 + x2 + ...+ xn',\n",
    "                      data=mydata)`\n",
    "\n",
    "disp = 0 avoids printing out information during the estimation:\n",
    "\n",
    ">`results_logit = reg_logit.fit(disp=0)`\n",
    "\n",
    "\n",
    "# Estimate probit model:\n",
    ">`reg_probit = smf.probit(formula='y ~ x1 + x2 + ...+ xn',\n",
    "                      data=mydata)\n",
    "results_probit = reg_probit.fit(disp=0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html Econ320Lab_class11_QualitativeEmpty.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "<hr />\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\">ECON320 Python Programming Laboratory</a></p>\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\">Professor <em> Paloma Lopez de mesa Moyano</em></a></p>\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\"><span style=\"color: #6666FF;\"><em>paloma.moyano@emory.edu</em></span></p>\n",
    "\n",
    "<p style=\"font-family:palatino; text-align: center;font-size: 15px\">Department of Economics</a></p>\n",
    "<p style=\"font-family:palatino; text-align: center; color: #012169;font-size: 15px\">Emory University</a></p>\n",
    "\n",
    "&nbsp;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
